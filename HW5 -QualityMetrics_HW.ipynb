{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij_zY4soDF2Z"
      },
      "source": [
        "# Cross-validation riddle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUCsY5OlDJPl"
      },
      "source": [
        "Here's a small example of cross-validation done wrongly. Can you spot the problem?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mSUzkXsC-R4H"
      },
      "outputs": [],
      "source": [
        "# Some imports...\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyDp3Xc_DaDM"
      },
      "source": [
        "**Plan:**\n",
        "\n",
        "- Let's create a binary classification dataset where targets are completely independent from the features\n",
        "  - *(i.e. no model could ever predict them well)*\n",
        "- We'll do some simple feature selection\n",
        "- And cross-validate a model on this data\n",
        "\n",
        "**Q:** what accuracy do we expect (classes are even)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHx51DKP8Rcf"
      },
      "source": [
        "We'll start from writing a class to select the best features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rRNmKZJJ8W7x"
      },
      "outputs": [],
      "source": [
        "class FeatureSelector:\n",
        "  def __init__(self, num_features):\n",
        "    self.n = num_features # number of best features to select\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # Select features that describe the targets best, i.e. have\n",
        "    # highest correlation with them:\n",
        "    covariance = ((X - X.mean(axis=0)) * (y[:,np.newaxis] - y.mean())).mean(axis=0)\n",
        "    self.best_feature_ids = np.argsort(np.abs(covariance))[-self.n:]\n",
        "\n",
        "  def transform(self, X):\n",
        "    return X[:,self.best_feature_ids]\n",
        "\n",
        "  def fit_transform(self, X, y):\n",
        "    self.fit(X, y)\n",
        "    return self.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mu9gHgNBk_V",
        "outputId": "43c7b62c-cd2c-406e-d08f-ac8d1c3af9c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score is 0.99\n"
          ]
        }
      ],
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "num_features_total = 1000\n",
        "num_features_best = 100\n",
        "\n",
        "N = 100\n",
        "#N = 10000\n",
        "# Dataset generation\n",
        "X = np.random.normal(size=(N, num_features_total))\n",
        "y = np.random.randint(2, size=N)\n",
        "\n",
        "# Feature selection:\n",
        "X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
        "# Simple classification model\n",
        "#model = LinearSVC()\n",
        "\n",
        "#model.fit(X_train , y_train)\n",
        "#predict =model.predict(X_test)\n",
        "#print (accuracy_score(y_test, predict))\n",
        "\n",
        "# Estimatin accuracy using cross-validation:\n",
        "cv_score = cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
        "#cv_score = cross_val_score(model, X, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
        "print(f\"CV score is {cv_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afadN3ZVFKjF"
      },
      "source": [
        "What's going on?! Why accuracy is so high?\n",
        "\n",
        "Maybe it just happened by chance? Let's repeat this experiment many times and histogram the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "QDbOMXnuC6uw",
        "outputId": "6e75a369-13f4-4179-b3d6-7f7d780c1b29"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "num_features_total = 1000\n",
        "num_features_best = 100\n",
        "\n",
        "N = 100\n",
        "def experiment():\n",
        "  # Dataset generation\n",
        "  X = np.random.normal(size=(N, num_features_total))\n",
        "  y = np.random.randint(2, size=N)\n",
        "\n",
        "  # Feature selection:\n",
        "  X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
        "\n",
        "  # Simple classification model\n",
        "  model = LinearSVC()\n",
        "\n",
        "  # Estimatin accuracy using cross-validation:\n",
        "  return cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
        "  #return cross_val_score(model, X, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
        "\n",
        "results = [experiment() for _ in range(100)]\n",
        "plt.hist(results, bins=10);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMYRjjqOLB5Z"
      },
      "source": [
        "## Task 1 (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bLaEypoF5pb"
      },
      "source": [
        "Explain why the estimated model accuracy is not 50% on a dataset where targets were generated **independently from the features (!!!)**.\n",
        "\n",
        "Find and fix the problem (don't change the dataset generation or its parameters - `num_features_total`, `num_features_best`, `N`).\n",
        "\n",
        "*Hint: the problem is in the overall logic, and not a bug in the code.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The Problem is that we are doing feature selection which means that we are getting rid of the features that are loosly correlated with the data and taking the best features (even if the features are generated randomly but we are taking the best random features there is).\n",
        "\n",
        "below we are trying to see how not taking feature selection is going to affect the accuracy"
      ],
      "metadata": {
        "id": "VQLNdCKD7_37"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EfT36WPTLyqB",
        "outputId": "fefd224f-cee1-4359-a53c-fb603fb3df14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score is 0.48\n"
          ]
        }
      ],
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "num_features_total = 1000\n",
        "num_features_best = 100\n",
        "\n",
        "N = 100\n",
        "#N = 10000\n",
        "# Dataset generation\n",
        "X = np.random.normal(size=(N, num_features_total))\n",
        "y = np.random.randint(2, size=N)\n",
        "\n",
        "# Feature selection:\n",
        "#X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
        "# Simple classification model\n",
        "model = LinearSVC()\n",
        "\n",
        "#model.fit(X_train , y_train)\n",
        "#predict =model.predict(X_test)\n",
        "#print (accuracy_score(y_test, predict))\n",
        "\n",
        "# Estimatin accuracy using cross-validation:\n",
        "#cv_score = cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
        "cv_score = cross_val_score(model, X, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
        "print(f\"CV score is {cv_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "on the other hand : the Cv score does not reach the value of 0.5 exactly becuase of: First the small number of the data as input (N = 100) and Second the Cross-Validation step on the data, Third the number target input from class (0) dosen't match number of target input from the other class (1)"
      ],
      "metadata": {
        "id": "t6unl0f18x7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (len([t  for t in y  if t ==0 ]))"
      ],
      "metadata": {
        "id": "Ninagbsh9bFr",
        "outputId": "fcd498e1-c9c2-44af-d129-c36371d86d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWXH9KUuu8qE"
      },
      "source": [
        "## Task 2 (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcF_iCFLu8qF"
      },
      "source": [
        "Let's come back to Task 3 of Data Handling HW.\n",
        "Build a model with KNeighborsClassifier to get a higher accuracy on 5-fold Cross Validation than you achieve using your previosly fitted model (you can just copy the params from the previous notebook). \n",
        "\n",
        "Use `sklearn.model_selection.GridSearchCV` to find best parameters.  You may check the parameters'  description as follows:\n",
        "``` python\n",
        "help(KNeighborsClassifier)\n",
        "``` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8sWqS04Iu8qF",
        "outputId": "674d77e1-a5d9-4eef-dd5f-ffb76e68be1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-24 07:13:44--  https://raw.githubusercontent.com/HSE-LAMBDA/MLDM-2022/main/01-intro/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60302 (59K) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "\rtrain.csv             0%[                    ]       0  --.-KB/s               \rtrain.csv           100%[===================>]  58.89K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-12-24 07:13:44 (53.4 MB/s) - ‘train.csv’ saved [60302/60302]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/HSE-LAMBDA/MLDM-2022/main/01-intro/train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RieVv-KKu8qF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "data = pd.read_csv(\"train.csv\", index_col='PassengerId')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_selection_and_preprocessing(dataset):\n",
        "  #getting rid of tickets and cabins numbers\n",
        "  data = dataset.drop(['Ticket','Cabin'],axis =1)\n",
        "  \n",
        "  # droping names \n",
        "  data = data.drop(['Name'], axis=1)\n",
        "\n",
        "  # convert sex from catigorical to numerical\n",
        "  data['Sex'] = data['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
        "  \n",
        "\n",
        "  #messuring the family for each passenger and creating a new feature which is IsAlone \n",
        "\n",
        "  data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
        "  data['IsAlone'] = 0\n",
        "  data.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n",
        "  data = data.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
        "\n",
        "  #fill embarked missing values and convert to numerical\n",
        "  freq_port = data.Embarked.dropna().mode()[0]\n",
        "  data['Embarked'] = data['Embarked'].fillna(freq_port)\n",
        "  data['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "\n",
        "  # convert fare into ranges  \n",
        "  # note that we can get those rages by using pd.qcut(data['Fare'], 4)\n",
        "\n",
        "  data['Fare'].fillna(data['Fare'].dropna().median(), inplace=True)\n",
        "  data.loc[ data['Fare'] <= 7.91, 'Fare'] = 0\n",
        "  data.loc[(data['Fare'] > 7.91) & (data['Fare'] <= 14.454), 'Fare'] = 1\n",
        "  data.loc[(data['Fare'] > 14.454) & (data['Fare'] <= 31), 'Fare']   = 2\n",
        "  data.loc[ data['Fare'] > 31, 'Fare'] = 3\n",
        "  data['Fare'] = data['Fare'].astype(int)\n",
        "\n",
        "\n",
        "  #fill na in Age with mean\n",
        "  mean_value=data['Age'].mean()\n",
        "  data['Age'] = data['Age'].fillna(mean_value)\n",
        "\n",
        "  #replace age based on bands into 5 catigories we can aquire those bands by running pd.qcut(data['Age'], 5)\n",
        "  data.loc[ data['Age'] <= 16, 'Age'] = 0\n",
        "  data.loc[(data['Age'] > 16) & (data['Age'] <= 32), 'Age'] = 1\n",
        "  data.loc[(data['Age'] > 32) & (data['Age'] <= 48), 'Age'] = 2\n",
        "  data.loc[(data['Age'] > 48) & (data['Age'] <= 64), 'Age'] = 3\n",
        "  data.loc[ data['Age'] > 64, 'Age'] = 4\n",
        "\n",
        "  data['Age'] = data['Age'].astype(int)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "Gj7JsE0hzYFJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = data.iloc[:-100]\n",
        "data_test = data.iloc[-100:]"
      ],
      "metadata": {
        "id": "Cda3BG5b2c3B"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = KNeighborsClassifier()\n",
        "\n",
        "k_range = list(range(1, 10))\n",
        "param_grid = dict(n_neighbors=k_range)\n",
        "\n",
        "gscv = GridSearchCV(base_model, param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
        "\n",
        "X = feature_selection_and_preprocessing(\n",
        "        data_test.drop('Survived', axis=1)\n",
        "    )\n",
        "y = data_test['Survived']\n",
        "gscv.fit(X, y)\n",
        "print(gscv.best_params_)"
      ],
      "metadata": {
        "id": "CJ5Ms5fG0XjS",
        "outputId": "95089199-e967-4a37-b7c1-f7b5a72e5edb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_neighbors': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = KNeighborsClassifier(\n",
        "    n_neighbors=gscv.best_params_['n_neighbors']\n",
        ")"
      ],
      "metadata": {
        "id": "PXuE9Myw0akk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    feature_selection_and_preprocessing(\n",
        "        data_train.drop('Survived', axis=1)\n",
        "    ),\n",
        "    data_train['Survived']\n",
        ")\n"
      ],
      "metadata": {
        "id": "qiC30-2QzdTS",
        "outputId": "6083612e-7610-473e-e225-4cc875b53cd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(\n",
        "    feature_selection_and_preprocessing(\n",
        "        data_test.drop('Survived', axis=1)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "78qplD8D2u04"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test accuracy:\", accuracy_score(\n",
        "    data_test['Survived'],\n",
        "    test_predictions\n",
        "))"
      ],
      "metadata": {
        "id": "xXZTPqaK2zHn",
        "outputId": "c0112ce2-a13f-48f5-f7a7-7eb41aca616d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "as we could see theGridSearch yielded the same results for the parmeter 'n-neighbors' that we used in the previous HW hence the same accuracy was produced"
      ],
      "metadata": {
        "id": "qmO-Ugbw-y_9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Od2yQpLxzQ6n"
      },
      "execution_count": 29,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "QualityMetrics_HW.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}